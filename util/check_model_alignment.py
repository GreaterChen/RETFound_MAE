#!/usr/bin/env python3
"""
æ£€æŸ¥PyTorchæƒé‡å’ŒPaddlePaddleæ¨¡å‹å‚æ•°å¯¹é½æƒ…å†µ
"""

import os
import paddle
import numpy as np
from models_vit import RETFound_mae
from collections import OrderedDict


def load_pytorch_weights_info(pytorch_model_path):
    """åŠ è½½å¹¶åˆ†æPyTorchæƒé‡æ–‡ä»¶ä¿¡æ¯"""
    try:
        import torch
        print(f"ğŸ“¥ åŠ è½½PyTorchæƒé‡æ–‡ä»¶: {pytorch_model_path}")
        
        # åŠ è½½æƒé‡æ–‡ä»¶
        checkpoint = torch.load(pytorch_model_path, map_location='cpu', weights_only=False)
        
        # å¤„ç†ä¸åŒçš„æƒé‡æ ¼å¼
        if isinstance(checkpoint, dict):
            if 'model' in checkpoint:
                state_dict = checkpoint['model']
                print("æƒé‡æ ¼å¼: checkpoint['model']")
            elif 'state_dict' in checkpoint:
                state_dict = checkpoint['state_dict']
                print("æƒé‡æ ¼å¼: checkpoint['state_dict']")
            else:
                state_dict = checkpoint
                print("æƒé‡æ ¼å¼: ç›´æ¥state_dict")
        else:
            state_dict = checkpoint
            print("æƒé‡æ ¼å¼: æƒé‡å¼ é‡")
        
        # æ¸…ç†æƒé‡é”®å
        cleaned_weights = OrderedDict()
        for key, value in state_dict.items():
            # ç§»é™¤å¯èƒ½çš„å‰ç¼€
            clean_key = key.replace('module.', '').replace('backbone.', '')
            cleaned_weights[clean_key] = value
        
        print(f"ğŸ” PyTorchæƒé‡æ–‡ä»¶åŒ…å« {len(cleaned_weights)} ä¸ªå‚æ•°")
        print(f"ğŸ“Š æ€»å‚æ•°é‡: {sum(v.numel() for v in cleaned_weights.values()):,}")
        
        return cleaned_weights
        
    except Exception as e:
        print(f"âŒ åŠ è½½PyTorchæƒé‡å¤±è´¥: {e}")
        return None


def analyze_paddle_model_structure(model):
    """åˆ†æPaddlePaddleæ¨¡å‹ç»“æ„"""
    print(f"ğŸ” PaddlePaddleæ¨¡å‹ç»“æ„åˆ†æ:")
    
    model_state_dict = model.state_dict()
    print(f"ğŸ“Š æ¨¡å‹åŒ…å« {len(model_state_dict)} ä¸ªå‚æ•°")
    
    # ä¿®å¤æ ¼å¼åŒ–é”™è¯¯
    total_params = sum(p.numel().item() for p in model_state_dict.values())
    print(f"ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}")
    
    return model_state_dict


def detailed_parameter_comparison(pytorch_weights, paddle_state_dict):
    """è¯¦ç»†çš„å‚æ•°å¯¹æ¯”åˆ†æ"""
    print("\n" + "="*60)
    print("ğŸ“‹ è¯¦ç»†å‚æ•°å¯¹æ¯”åˆ†æ")
    print("="*60)
    
    # åˆ†ç±»æ•´ç†å‚æ•°
    pytorch_keys = set(pytorch_weights.keys())
    paddle_keys = set(paddle_state_dict.keys())
    
    # æ‰¾å‡ºåŒ¹é…çš„å‚æ•°
    matched_keys = pytorch_keys & paddle_keys
    missing_in_paddle = pytorch_keys - paddle_keys
    missing_in_pytorch = paddle_keys - pytorch_keys
    
    print(f"\nâœ… åŒ¹é…çš„å‚æ•°: {len(matched_keys)}")
    for key in sorted(matched_keys):
        pytorch_shape = pytorch_weights[key].shape
        paddle_shape = paddle_state_dict[key].shape
        
        if pytorch_shape == paddle_shape:
            status = "âœ… å½¢çŠ¶åŒ¹é…"
        else:
            status = f"âš ï¸ å½¢çŠ¶ä¸åŒ¹é… PyTorch:{pytorch_shape} vs Paddle:{paddle_shape}"
        
        print(f"  {key}: {status}")
    
    print(f"\nâŒ PaddlePaddleä¸­ç¼ºå¤±çš„å‚æ•°: {len(missing_in_paddle)}")
    for key in sorted(missing_in_paddle):
        pytorch_shape = pytorch_weights[key].shape
        print(f"  {key}: {pytorch_shape}")
    
    print(f"\nâŒ PyTorchä¸­ç¼ºå¤±çš„å‚æ•°: {len(missing_in_pytorch)}")
    for key in sorted(missing_in_pytorch):
        paddle_shape = paddle_state_dict[key].shape
        print(f"  {key}: {paddle_shape}")
    
    # åˆ†æç¼ºå¤±å‚æ•°çš„ç±»å‹
    print(f"\nğŸ” ç¼ºå¤±å‚æ•°ç±»å‹åˆ†æ:")
    
    # åˆ†ædecoderç›¸å…³å‚æ•°
    decoder_keys = [k for k in missing_in_paddle if 'decoder' in k or 'mask_token' in k]
    if decoder_keys:
        print(f"  ğŸ”§ Decoderç›¸å…³å‚æ•° ({len(decoder_keys)}ä¸ª):")
        for key in decoder_keys[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            print(f"    {key}")
        if len(decoder_keys) > 10:
            print(f"    ... è¿˜æœ‰ {len(decoder_keys)-10} ä¸ªdecoderå‚æ•°")
    
    # åˆ†æåˆ†ç±»å¤´å‚æ•°
    head_keys = [k for k in missing_in_paddle if 'head' in k]
    if head_keys:
        print(f"  ğŸ¯ åˆ†ç±»å¤´ç›¸å…³å‚æ•° ({len(head_keys)}ä¸ª):")
        for key in head_keys:
            print(f"    {key}")
    
    # åˆ†æå…¶ä»–å‚æ•°
    other_keys = [k for k in missing_in_paddle if 'decoder' not in k and 'mask_token' not in k and 'head' not in k]
    if other_keys:
        print(f"  ğŸ“¦ å…¶ä»–å‚æ•° ({len(other_keys)}ä¸ª):")
        for key in other_keys:
            print(f"    {key}")
    
    return {
        'matched_keys': matched_keys,
        'missing_in_paddle': missing_in_paddle,
        'missing_in_pytorch': missing_in_pytorch,
        'decoder_keys': decoder_keys if 'decoder_keys' in locals() else [],
        'head_keys': head_keys if 'head_keys' in locals() else []
    }


def analyze_mae_vs_classification_model(pytorch_weights):
    """åˆ†æMAEæ¨¡å‹ä¸åˆ†ç±»æ¨¡å‹çš„å·®å¼‚"""
    print(f"\nğŸ” MAE vs åˆ†ç±»æ¨¡å‹æ¶æ„åˆ†æ:")
    
    # åˆ†æencoderå‚æ•°
    encoder_keys = []
    decoder_keys = []
    head_keys = []
    other_keys = []
    
    for key in pytorch_weights.keys():
        if any(pattern in key for pattern in ['patch_embed', 'cls_token', 'pos_embed', 'blocks', 'norm']):
            # æ£€æŸ¥æ˜¯å¦æ˜¯decoderå—
            if 'decoder' not in key:
                encoder_keys.append(key)
            else:
                decoder_keys.append(key)
        elif 'decoder' in key or 'mask_token' in key:
            decoder_keys.append(key)
        elif 'head' in key:
            head_keys.append(key)
        else:
            other_keys.append(key)
    
    print(f"  ğŸ—ï¸  Encoderå‚æ•°: {len(encoder_keys)}ä¸ª")
    print(f"     - patch_embed: {len([k for k in encoder_keys if 'patch_embed' in k])}ä¸ª")
    print(f"     - cls_token/pos_embed: {len([k for k in encoder_keys if 'cls_token' in k or 'pos_embed' in k])}ä¸ª")
    print(f"     - transformer blocks: {len([k for k in encoder_keys if 'blocks' in k])}ä¸ª")
    print(f"     - norm layers: {len([k for k in encoder_keys if 'norm' in k and 'blocks' not in k])}ä¸ª")
    
    print(f"  ğŸ”§ Decoderå‚æ•°: {len(decoder_keys)}ä¸ª")
    if decoder_keys:
        print(f"     - decoder_blocks: {len([k for k in decoder_keys if 'decoder_blocks' in k])}ä¸ª")
        print(f"     - decoder_embed: {len([k for k in decoder_keys if 'decoder_embed' in k])}ä¸ª")
        print(f"     - decoder_norm: {len([k for k in decoder_keys if 'decoder_norm' in k])}ä¸ª")
        print(f"     - decoder_pred: {len([k for k in decoder_keys if 'decoder_pred' in k])}ä¸ª")
        print(f"     - mask_token: {len([k for k in decoder_keys if 'mask_token' in k])}ä¸ª")
        print(f"     - decoder_pos_embed: {len([k for k in decoder_keys if 'decoder_pos_embed' in k])}ä¸ª")
    
    print(f"  ğŸ¯ åˆ†ç±»å¤´å‚æ•°: {len(head_keys)}ä¸ª")
    for key in head_keys:
        print(f"     - {key}: {pytorch_weights[key].shape}")
    
    print(f"  ğŸ“¦ å…¶ä»–å‚æ•°: {len(other_keys)}ä¸ª")
    for key in other_keys:
        print(f"     - {key}: {pytorch_weights[key].shape}")
    
    return {
        'encoder_keys': encoder_keys,
        'decoder_keys': decoder_keys,
        'head_keys': head_keys,
        'other_keys': other_keys
    }


def suggest_alignment_fixes(comparison_result, mae_analysis):
    """å»ºè®®å‚æ•°å¯¹é½ä¿®å¤æ–¹æ¡ˆ"""
    print(f"\nğŸ”§ å‚æ•°å¯¹é½ä¿®å¤å»ºè®®:")
    
    missing_in_paddle = comparison_result['missing_in_paddle']
    head_keys = mae_analysis['head_keys']
    decoder_keys = mae_analysis['decoder_keys']
    
    # 1. Decoderå‚æ•°å¤„ç†
    if decoder_keys:
        print(f"  1ï¸âƒ£ Decoderå‚æ•°å¤„ç†:")
        print(f"     - PyTorchæƒé‡åŒ…å«MAE decoderéƒ¨åˆ† ({len(decoder_keys)}ä¸ªå‚æ•°)")
        print(f"     - PaddlePaddleæ¨¡å‹åªéœ€è¦encoderéƒ¨åˆ†")
        print(f"     âœ… å»ºè®®: åœ¨æƒé‡è½¬æ¢æ—¶è¿‡æ»¤æ‰decoderç›¸å…³å‚æ•°")
        print(f"     ğŸ“ å®ç°: åœ¨weight_converter.pyä¸­æ·»åŠ decoderå‚æ•°è¿‡æ»¤")
    
    # 2. åˆ†ç±»å¤´å‚æ•°å¤„ç†
    if head_keys:
        print(f"  2ï¸âƒ£ åˆ†ç±»å¤´å‚æ•°å¤„ç†:")
        print(f"     - PyTorchæƒé‡åŒ…å«åˆ†ç±»å¤´: {head_keys}")
        for key in head_keys:
            print(f"       {key}: éœ€è¦æ·»åŠ åˆ°PaddlePaddleæ¨¡å‹")
        print(f"     âœ… å»ºè®®: ç¡®ä¿PaddlePaddleæ¨¡å‹çš„åˆ†ç±»å¤´ä¸PyTorchä¸€è‡´")
    else:
        print(f"  2ï¸âƒ£ åˆ†ç±»å¤´å‚æ•°ç¼ºå¤±:")
        print(f"     - PyTorchæƒé‡ç¼ºå°‘åˆ†ç±»å¤´å‚æ•°")
        print(f"     âœ… å»ºè®®: è¿™æ˜¯æ­£å¸¸çš„ï¼Œåˆ†ç±»å¤´é€šå¸¸éœ€è¦é‡æ–°è®­ç»ƒ")
    
    # 3. å‚æ•°é”®åå¯¹é½
    print(f"  3ï¸âƒ£ å‚æ•°é”®åå¯¹é½:")
    print(f"     - åŒ¹é…å‚æ•°: {len(comparison_result['matched_keys'])}ä¸ª")
    print(f"     - éœ€è¦ä¿®å¤çš„ç¼ºå¤±å‚æ•°: {len(missing_in_paddle - set(decoder_keys))}ä¸ª")
    
    # 4. å…·ä½“ä¿®å¤æ­¥éª¤
    print(f"\nğŸ“‹ å…·ä½“ä¿®å¤æ­¥éª¤:")
    print(f"  1. ä¿®æ”¹æƒé‡è½¬æ¢å™¨ä»¥è¿‡æ»¤decoderå‚æ•°")
    print(f"  2. ç¡®ä¿linearå±‚æƒé‡æ­£ç¡®è½¬ç½®")
    print(f"  3. å¤„ç†åˆ†ç±»å¤´æƒé‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰")
    print(f"  4. éªŒè¯è½¬æ¢åçš„æƒé‡å®Œæ•´æ€§")


def main():
    """ä¸»å‡½æ•°"""
    print("RETFound å‚æ•°å¯¹é½æ£€æŸ¥å·¥å…·")
    print("="*50)
    
    # 1. åŠ è½½PyTorchæƒé‡ä¿¡æ¯
    pytorch_model_path = "/home/chenlb24/RETFound_MAE/RETFound_mae_meh.pth"
    
    if not os.path.exists(pytorch_model_path):
        print(f"âŒ PyTorchæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {pytorch_model_path}")
        return
    
    pytorch_weights = load_pytorch_weights_info(pytorch_model_path)
    if pytorch_weights is None:
        return
    
    # 2. åˆ›å»ºå’Œåˆ†æPaddlePaddleæ¨¡å‹
    print(f"\nğŸ—ï¸  åˆ›å»ºPaddlePaddleæ¨¡å‹...")
    paddle_model = RETFound_mae(num_classes=1000)
    paddle_state_dict = analyze_paddle_model_structure(paddle_model)
    
    # 3. è¯¦ç»†å‚æ•°å¯¹æ¯”
    comparison_result = detailed_parameter_comparison(pytorch_weights, paddle_state_dict)
    
    # 4. MAE vs åˆ†ç±»æ¨¡å‹åˆ†æ
    mae_analysis = analyze_mae_vs_classification_model(pytorch_weights)
    
    # 5. å»ºè®®ä¿®å¤æ–¹æ¡ˆ
    suggest_alignment_fixes(comparison_result, mae_analysis)
    
    print(f"\nâœ… å‚æ•°å¯¹é½æ£€æŸ¥å®Œæˆ!")


if __name__ == "__main__":
    main() 