#!/usr/bin/env python3
"""
RETFound PyTorchæƒé‡åŠ è½½åˆ°PaddlePaddleç¤ºä¾‹è„šæœ¬

æ­¤è„šæœ¬æ¼”ç¤ºäº†å¦‚ä½•å°†RETFoundçš„PyTorché¢„è®­ç»ƒæƒé‡è½¬æ¢å¹¶åŠ è½½åˆ°PaddlePaddleæ¨¡å‹ä¸­ã€‚
æ”¯æŒä»HuggingFace Hubæˆ–æœ¬åœ°æ–‡ä»¶åŠ è½½æƒé‡ã€‚
"""

import os
import paddle
import numpy as np
from models_vit import RETFound_mae, RETFound_dinov2
from util.weight_converter import convert_retfound_weights, load_converted_weights_to_model


def download_huggingface_model(model_name, cache_dir="./models"):
    """
    ä»HuggingFace Hubä¸‹è½½RETFoundæ¨¡å‹æƒé‡
    
    Args:
        model_name: æ¨¡å‹åç§°ï¼Œå¦‚ "ycxia/RETFound_MAE"
        cache_dir: æ¨¡å‹ç¼“å­˜ç›®å½•
    """
    try:
        from huggingface_hub import hf_hub_download
        import torch
        
        print(f"Downloading {model_name} from HuggingFace Hub...")
        
        # ä¸‹è½½æ¨¡å‹æƒé‡æ–‡ä»¶
        model_file = hf_hub_download(
            repo_id=model_name,
            filename="pytorch_model.bin",  # æˆ– "model.safetensors"
            cache_dir=cache_dir
        )
        
        print(f"Model downloaded to: {model_file}")
        return model_file
        
    except ImportError:
        print("è¯·å®‰è£…huggingface_hub: pip install huggingface_hub")
        return None
    except Exception as e:
        print(f"ä¸‹è½½æ¨¡å‹å¤±è´¥: {e}")
        return None


def load_retfound_mae_example():
    """RETFound MAEæ¨¡å‹åŠ è½½ç¤ºä¾‹"""
    print("=== RETFound MAE æ¨¡å‹åŠ è½½ç¤ºä¾‹ ===")
    
    # 1. åˆ›å»ºPaddlePaddleæ¨¡å‹
    model = RETFound_mae(num_classes=1000)
    print(f"Created RETFound MAE model with {sum(p.numel() for p in model.parameters())} parameters")
    
    # 2. é€‰æ‹©æƒé‡æ¥æº
    pytorch_model_path = None
    
    # é€‰é¡¹1: ä»HuggingFaceä¸‹è½½
    use_huggingface = True  # è®¾ç½®ä¸ºTrueä½¿ç”¨HuggingFaceï¼ŒFalseä½¿ç”¨æœ¬åœ°æ–‡ä»¶
    
    if use_huggingface:
        pytorch_model_path = download_huggingface_model("ycxia/RETFound_MAE")
    else:
        # é€‰é¡¹2: ä½¿ç”¨æœ¬åœ°PyTorchæƒé‡æ–‡ä»¶
        pytorch_model_path = "path/to/your/pytorch_retfound_mae.pth"
        
        if not os.path.exists(pytorch_model_path):
            print(f"æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨: {pytorch_model_path}")
            print("è¯·ä¸‹è½½RETFound MAEæƒé‡æˆ–è®¾ç½®æ­£ç¡®çš„æ–‡ä»¶è·¯å¾„")
            return None
    
    if pytorch_model_path is None:
        print("æ— æ³•è·å–PyTorchæ¨¡å‹æƒé‡")
        return None
    
    # 3. è½¬æ¢å¹¶åŠ è½½æƒé‡
    try:
        success = model.load_pytorch_weights(pytorch_model_path)
        
        if success:
            print("âœ… æƒé‡åŠ è½½æˆåŠŸï¼")
            
            # 4. æµ‹è¯•æ¨¡å‹æ¨ç†
            test_model_inference(model)
            
            return model
        else:
            print("âŒ æƒé‡åŠ è½½å¤±è´¥")
            return None
            
    except Exception as e:
        print(f"åŠ è½½æƒé‡æ—¶å‡ºé”™: {e}")
        return None


def test_model_inference(model):
    """æµ‹è¯•æ¨¡å‹æ¨ç†"""
    print("\n=== æµ‹è¯•æ¨¡å‹æ¨ç† ===")
    
    # åˆ›å»ºéšæœºè¾“å…¥
    batch_size = 2
    input_tensor = paddle.randn([batch_size, 3, 224, 224])
    
    # è®¾ç½®è¯„ä¼°æ¨¡å¼
    model.eval()
    
    with paddle.no_grad():
        # å‰å‘ä¼ æ’­
        output = model(input_tensor)
        print(f"è¾“å…¥å½¢çŠ¶: {input_tensor.shape}")
        print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"è¾“å‡ºèŒƒå›´: [{output.min().item():.4f}, {output.max().item():.4f}]")
        
        # è·å–ç‰¹å¾
        features = model.forward_features(input_tensor)
        print(f"ç‰¹å¾å½¢çŠ¶: {features.shape}")
        
    print("âœ… æ¨¡å‹æ¨ç†æµ‹è¯•é€šè¿‡ï¼")


def manual_weight_conversion_example():
    """æ‰‹åŠ¨æƒé‡è½¬æ¢ç¤ºä¾‹"""
    print("\n=== æ‰‹åŠ¨æƒé‡è½¬æ¢ç¤ºä¾‹ ===")
    
    # PyTorchæƒé‡æ–‡ä»¶è·¯å¾„
    pytorch_model_path = "path/to/pytorch_model.pth"
    paddle_model_path = "converted_retfound_paddle.pdparams"
    
    if not os.path.exists(pytorch_model_path):
        print(f"PyTorchæƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {pytorch_model_path}")
        return False
    
    # è½¬æ¢æƒé‡
    print("å¼€å§‹è½¬æ¢PyTorchæƒé‡...")
    success = convert_retfound_weights(pytorch_model_path, paddle_model_path)
    
    if success:
        print(f"âœ… æƒé‡è½¬æ¢æˆåŠŸï¼Œä¿å­˜è‡³: {paddle_model_path}")
        
        # åŠ è½½åˆ°æ¨¡å‹
        model = RETFound_mae(num_classes=1000)
        load_success = load_converted_weights_to_model(model, paddle_model_path, strict=False)
        
        if load_success:
            print("âœ… æƒé‡åŠ è½½åˆ°æ¨¡å‹æˆåŠŸï¼")
            return True
        else:
            print("âŒ æƒé‡åŠ è½½åˆ°æ¨¡å‹å¤±è´¥")
            return False
    else:
        print("âŒ æƒé‡è½¬æ¢å¤±è´¥")
        return False


def compare_models_output():
    """æ¯”è¾ƒPyTorchå’ŒPaddlePaddleæ¨¡å‹è¾“å‡ºï¼ˆå¦‚æœä¸¤ä¸ªæ¡†æ¶éƒ½å¯ç”¨ï¼‰"""
    print("\n=== æ¨¡å‹è¾“å‡ºå¯¹æ¯” ===")
    
    try:
        import torch
        import torch.nn as nn
        
        # è¿™é‡Œéœ€è¦æœ‰PyTorchç‰ˆæœ¬çš„RETFoundæ¨¡å‹
        # ç”±äºæˆ‘ä»¬ä¸»è¦åœ¨PaddlePaddleç¯å¢ƒä¸­ï¼Œè¿™ä¸ªåŠŸèƒ½ä½œä¸ºç¤ºä¾‹
        print("å¦‚æœæœ‰PyTorchç‰ˆæœ¬ï¼Œå¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œè¾“å‡ºå¯¹æ¯”")
        print("ç¡®ä¿ä¸¤ä¸ªæ¨¡å‹ä½¿ç”¨ç›¸åŒçš„è¾“å…¥å’Œæƒé‡")
        
    except ImportError:
        print("PyTorchæœªå®‰è£…ï¼Œè·³è¿‡æ¨¡å‹å¯¹æ¯”")


def main():
    """ä¸»å‡½æ•°"""
    print("RETFound PyTorchæƒé‡è½¬æ¢å’ŒåŠ è½½ç¤ºä¾‹")
    print("=" * 50)
    
    # ç¤ºä¾‹1: åŠ è½½RETFound MAEæ¨¡å‹
    model = load_retfound_mae_example()
    
    if model is not None:
        print("\nğŸ‰ RETFoundæ¨¡å‹å·²æˆåŠŸåŠ è½½åˆ°PaddlePaddle!")
        print("\nä½ ç°åœ¨å¯ä»¥ä½¿ç”¨è¿™ä¸ªæ¨¡å‹è¿›è¡Œ:")
        print("- å¾®è°ƒè®­ç»ƒ")
        print("- ç‰¹å¾æå–") 
        print("- çœ¼åº•å›¾åƒåˆ†æ")
        print("- è¿ç§»å­¦ä¹ ")
        
        # ä¿å­˜PaddlePaddleæ ¼å¼çš„æ¨¡å‹
        paddle_model_save_path = "retfound_mae_paddle.pdparams"
        paddle.save(model.state_dict(), paddle_model_save_path)
        print(f"\nğŸ’¾ PaddlePaddleæ¨¡å‹å·²ä¿å­˜è‡³: {paddle_model_save_path}")
        
    else:
        print("\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé‡æ–‡ä»¶å’Œè½¬æ¢è¿‡ç¨‹")


if __name__ == "__main__":
    # è®¾ç½®PaddlePaddleè®¾å¤‡
    paddle.set_device('gpu' if paddle.is_compiled_with_cuda() else 'cpu')
    print(f"ä½¿ç”¨è®¾å¤‡: {paddle.get_device()}")
    
    main() 